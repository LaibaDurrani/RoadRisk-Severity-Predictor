{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jfghOFNiqmd0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = pd.read_csv(\"/content/df_cleaned.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTfVyN0arNeM",
        "outputId": "33812c48-ecab-4035-defa-7dc319ac1abe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3484717098.py:1: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_cleaned = pd.read_csv(\"/content/df_cleaned.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xTCLYOXvqQ8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360b2fa2-c348-4151-bce8-9eb498f0a558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DECODING CATEGORICAL VARIABLES...\n"
          ]
        }
      ],
      "source": [
        "print(\"DECODING CATEGORICAL VARIABLES...\")\n",
        "\n",
        "def decode_all_categoricals(df):\n",
        "    \"\"\"\n",
        "    Replace all numeric codes with descriptive labels\n",
        "    \"\"\"\n",
        "    df_decoded = df.copy()\n",
        "\n",
        "    # Define comprehensive mapping dictionaries\n",
        "    mappings = {\n",
        "        # Collision severity\n",
        "        'collision_severity': {\n",
        "            1: 'Fatal', 2: 'Serious', 3: 'Slight', -1: 'Data Missing'\n",
        "        },\n",
        "\n",
        "        # Day of week\n",
        "        'day_of_week': {\n",
        "            1: 'Sunday', 2: 'Monday', 3: 'Tuesday', 4: 'Wednesday',\n",
        "            5: 'Thursday', 6: 'Friday', 7: 'Saturday', -1: 'Data Missing'\n",
        "        },\n",
        "\n",
        "        # Road class\n",
        "        'first_road_class': {\n",
        "            1: 'Motorway', 2: 'A_Road_Motorway', 3: 'A_Road', 4: 'B_Road',\n",
        "            5: 'C_Road', 6: 'Unclassified', -1: 'Data Missing'\n",
        "        },\n",
        "\n",
        "        'second_road_class': {\n",
        "            1: 'Motorway', 2: 'A_Road_Motorway', 3: 'A_Road', 4: 'B_Road',\n",
        "            5: 'C_Road', 6: 'Unclassified', -1: 'Data Missing', 0: 'Not_at_Junction'\n",
        "        },\n",
        "\n",
        "        # Light conditions\n",
        "        'light_conditions': {\n",
        "            1: 'Daylight', 4: 'Darkness_Lights_Lit', 5: 'Darkness_Lights_Unlit',\n",
        "            6: 'Darkness_No_Lighting', 7: 'Darkness_Lighting_Unknown', -1: 'Data Missing'\n",
        "        },\n",
        "\n",
        "        # Weather conditions\n",
        "        'weather_conditions': {\n",
        "            1: 'Fine_No_High_Winds', 2: 'Raining_No_High_Winds', 3: 'Snowing_No_High_Winds',\n",
        "            4: 'Fine_High_Winds', 5: 'Raining_High_Winds', 6: 'Snowing_High_Winds',\n",
        "            7: 'Fog_or_Mist', 8: 'Other_Weather', 9: 'Unknown_Weather', -1: 'Data Missing'\n",
        "        },\n",
        "\n",
        "        # Urban/rural\n",
        "        'urban_or_rural_area': {\n",
        "            1: 'Urban', 2: 'Rural', 3: 'Unallocated', -1: 'Data Missing'\n",
        "        },\n",
        "\n",
        "        # Junction control\n",
        "        'junction_control': {\n",
        "            0: 'Not_at_Junction', 1: 'Authorised_Person', 2: 'Traffic_Signals',\n",
        "            3: 'Stop_Sign', 4: 'Give_Way_Uncontrolled', -1: 'Data Missing', 9: 'Unknown'\n",
        "        },\n",
        "\n",
        "        # Police attendance\n",
        "        'did_police_officer_attend_scene_of_accident': {\n",
        "            1: 'Police_Attended', 2: 'Police_Not_Attended',\n",
        "            3: 'Self_Reported', -1: 'Data Missing'\n",
        "        },\n",
        "\n",
        "        # Trunk road\n",
        "        'trunk_road_flag': {\n",
        "            1: 'Trunk_Road', 2: 'Non_Trunk_Road', -1: 'Data Missing'\n",
        "        },\n",
        "\n",
        "        'road_type': {\n",
        "            1: 'Roundabout',\n",
        "            2: 'One_Way_Street',\n",
        "            3: 'Dual_Carriageway',\n",
        "            6: 'Single_Carriageway',\n",
        "            7: 'Slip_Road',\n",
        "            9: 'Unknown_Road_Type',\n",
        "            12: 'One_Way_Slip_Road',\n",
        "            -1: 'Data_Missing'\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Apply all mappings\n",
        "    decoded_count = 0\n",
        "    for column_name, mapping_dict in mappings.items():\n",
        "        if column_name in df_decoded.columns:\n",
        "            new_column_name = f\"{column_name}_decoded\"\n",
        "            df_decoded[new_column_name] = df_decoded[column_name].map(mapping_dict)\n",
        "            decoded_count += 1\n",
        "            print(f\"Decoded {column_name} -> {new_column_name}\")\n",
        "\n",
        "    # Speed limit categories\n",
        "    if 'speed_limit' in df_decoded.columns:\n",
        "        df_decoded['speed_limit_category'] = pd.cut(\n",
        "            df_decoded['speed_limit'],\n",
        "            bins=[0, 20, 30, 40, 50, 60, 70, 1000],\n",
        "            labels=['20_mph_or_less', '21-30_mph', '31-40_mph', '41-50_mph',\n",
        "                   '51-60_mph', '61-70_mph', '70_plus_mph']\n",
        "        )\n",
        "        print(\"Created speed_limit_category\")\n",
        "\n",
        "    print(f\"Decoded {decoded_count} categorical variables\")\n",
        "    return df_decoded"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply decoding\n",
        "df_decoded = decode_all_categoricals(df_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w9k7_FircK7",
        "outputId": "a1310470-c5ba-49c9-c958-ec4dfe45e084"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded collision_severity -> collision_severity_decoded\n",
            "Decoded day_of_week -> day_of_week_decoded\n",
            "Decoded first_road_class -> first_road_class_decoded\n",
            "Decoded second_road_class -> second_road_class_decoded\n",
            "Decoded light_conditions -> light_conditions_decoded\n",
            "Decoded weather_conditions -> weather_conditions_decoded\n",
            "Decoded urban_or_rural_area -> urban_or_rural_area_decoded\n",
            "Decoded junction_control -> junction_control_decoded\n",
            "Decoded did_police_officer_attend_scene_of_accident -> did_police_officer_attend_scene_of_accident_decoded\n",
            "Decoded trunk_road_flag -> trunk_road_flag_decoded\n",
            "Decoded road_type -> road_type_decoded\n",
            "Created speed_limit_category\n",
            "Decoded 11 categorical variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CREATING FINAL CLEAN DATASET...\")\n",
        "\n",
        "def create_final_dataset(df, output_filename=\"road_safety_analysis_ready.csv\"):\n",
        "    \"\"\"\n",
        "    Create the final clean dataset for download\n",
        "    \"\"\"\n",
        "    df_final = df.copy()\n",
        "\n",
        "    # 1. Remove original coded columns where we have decoded versions\n",
        "    print(\"Removing original coded columns...\")\n",
        "    columns_to_remove = []\n",
        "    for col in df_final.columns:\n",
        "        if not col.endswith('_decoded') and not col.endswith('_category'):\n",
        "            # Check if this column has a decoded version\n",
        "            decoded_col = f\"{col}_decoded\"\n",
        "            if decoded_col in df_final.columns:\n",
        "                columns_to_remove.append(col)\n",
        "\n",
        "    # Also remove the intermediate calculated columns\n",
        "    intermediate_cols = ['number_of_vehicles', 'calculated_vehicle_count',\n",
        "                        'number_of_casualties', 'calculated_total_casualties',\n",
        "                        'severity_weight']\n",
        "\n",
        "    for col in intermediate_cols:\n",
        "        if col in df_final.columns and col not in columns_to_remove:\n",
        "            columns_to_remove.append(col)\n",
        "\n",
        "    df_final = df_final.drop(columns=columns_to_remove)\n",
        "    print(f\"   Removed {len(columns_to_remove)} original coded columns\")\n",
        "\n",
        "    # 2. Select and reorder columns for better organization\n",
        "    print(\"Organizing final columns...\")\n",
        "\n",
        "    # Define the ideal column order\n",
        "    column_order = [\n",
        "        # Core identifiers\n",
        "        'collision_index', 'collision_year', 'collision_ref_no',\n",
        "\n",
        "        # Date and time\n",
        "        'accident_date', 'accident_hour', 'time_period', 'accident_month',\n",
        "        'day_of_week_decoded', 'is_weekend',\n",
        "\n",
        "        # Location\n",
        "        'longitude', 'latitude', 'local_authority_ons_district',\n",
        "        'urban_or_rural_area_decoded', 'lsoa_of_accident_location',\n",
        "\n",
        "        # Severity and risk\n",
        "        'collision_severity_decoded', 'risk_score', 'risk_category',\n",
        "\n",
        "        # Vehicle information\n",
        "        'final_vehicle_count', 'unique_vehicle_types', 'avg_driver_age',\n",
        "        'male_driver_ratio', 'unique_manoeuvres', 'unique_journey_purposes',\n",
        "\n",
        "        # Casualty information\n",
        "        'final_total_casualties', 'fatal_casualties_count', 'pedestrian_casualties_count',\n",
        "        'avg_casualty_age', 'unique_casualty_types',\n",
        "\n",
        "        # Road infrastructure\n",
        "        'first_road_class_decoded', 'speed_limit', 'speed_limit_category',\n",
        "        'road_type', 'trunk_road_flag_decoded', 'is_major_road', 'is_high_speed',\n",
        "\n",
        "        # Junction information\n",
        "        'junction_detail', 'junction_control_decoded', 'has_complex_junction',\n",
        "\n",
        "        # Environmental conditions\n",
        "        'light_conditions_decoded', 'weather_conditions_decoded',\n",
        "        'poor_visibility', 'adverse_weather', 'poor_road_condition',\n",
        "\n",
        "        # Additional features\n",
        "        'police_force', 'did_police_officer_attend_scene_of_accident_decoded'\n",
        "    ]\n",
        "\n",
        "    # Filter to only existing columns\n",
        "    existing_columns = [col for col in column_order if col in df_final.columns]\n",
        "\n",
        "    # Add any remaining columns\n",
        "    remaining_columns = [col for col in df_final.columns if col not in existing_columns]\n",
        "\n",
        "    final_columns = existing_columns + remaining_columns\n",
        "    df_final = df_final[final_columns]\n",
        "\n",
        "    # 4. Generate summary report\n",
        "    print(\"\\n FINAL DATASET SUMMARY:\")\n",
        "    print(f\"   • Total records: {len(df_final):,}\")\n",
        "    print(f\"   • Total columns: {len(df_final.columns)}\")\n",
        "    print(f\"   • File saved as: {output_filename}\")\n",
        "\n",
        "    # Count decoded columns\n",
        "    decoded_cols = [col for col in df_final.columns if col.endswith('_decoded')]\n",
        "    print(f\"   • Decoded columns: {len(decoded_cols)}\")\n",
        "\n",
        "    if 'risk_category' in df_final.columns:\n",
        "        high_risk = (df_final['risk_category'] == 'High Risk').sum()\n",
        "        print(f\"   • High-risk collisions: {high_risk:,} ({high_risk/len(df_final)*100:.1f}%)\")\n",
        "\n",
        "    return df_final\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWcus1svvNh5",
        "outputId": "cdc161a8-65eb-4da9-c48f-a9965b4b4b8d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATING FINAL CLEAN DATASET...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create final dataset\n",
        "final_data = create_final_dataset(df_decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbEOHplwvag7",
        "outputId": "17019513-8838-4b89-a53d-50d42d355ccb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing original coded columns...\n",
            "   Removed 12 original coded columns\n",
            "Organizing final columns...\n",
            "\n",
            " FINAL DATASET SUMMARY:\n",
            "   • Total records: 52,657\n",
            "   • Total columns: 57\n",
            "   • File saved as: road_safety_analysis_ready.csv\n",
            "   • Decoded columns: 11\n",
            "   • High-risk collisions: 13,597 (25.8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxweXDIgvear",
        "outputId": "08999c0a-4b44-49b7-dcb3-11671126c048"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['collision_index', 'collision_year', 'collision_ref_no',\n",
              "       'accident_date', 'accident_hour', 'time_period', 'accident_month',\n",
              "       'day_of_week_decoded', 'is_weekend', 'longitude', 'latitude',\n",
              "       'local_authority_ons_district', 'urban_or_rural_area_decoded',\n",
              "       'lsoa_of_accident_location', 'collision_severity_decoded', 'risk_score',\n",
              "       'risk_category', 'final_vehicle_count', 'unique_vehicle_types',\n",
              "       'avg_driver_age', 'male_driver_ratio', 'unique_manoeuvres',\n",
              "       'unique_journey_purposes', 'final_total_casualties',\n",
              "       'fatal_casualties_count', 'pedestrian_casualties_count',\n",
              "       'avg_casualty_age', 'unique_casualty_types', 'first_road_class_decoded',\n",
              "       'speed_limit', 'speed_limit_category', 'trunk_road_flag_decoded',\n",
              "       'is_major_road', 'is_high_speed', 'junction_detail',\n",
              "       'junction_control_decoded', 'has_complex_junction',\n",
              "       'light_conditions_decoded', 'weather_conditions_decoded',\n",
              "       'poor_visibility', 'adverse_weather', 'poor_road_condition',\n",
              "       'police_force', 'did_police_officer_attend_scene_of_accident_decoded',\n",
              "       'location_easting_osgr', 'location_northing_osgr',\n",
              "       'local_authority_district', 'local_authority_highway',\n",
              "       'first_road_number', 'second_road_number', 'pedestrian_crossing',\n",
              "       'road_surface_conditions', 'special_conditions_at_site',\n",
              "       'carriageway_hazards', 'accident_year', 'second_road_class_decoded',\n",
              "       'road_type_decoded'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CREATING OPTIMIZED DATASET FOR MODEL TRAINING...\")\n",
        "\n",
        "def create_optimized_model_dataset(df, output_filename=\"road_safety_model_ready.csv\"):\n",
        "    \"\"\"\n",
        "    Create a clean dataset optimized for machine learning model training\n",
        "    \"\"\"\n",
        "    df_optimized = df.copy()\n",
        "\n",
        "    # 1. REMOVE DUPLICATE AND UNNECESSARY COLUMNS\n",
        "    print(\"Removing duplicate and unnecessary columns...\")\n",
        "\n",
        "    columns_to_remove = [\n",
        "        # Duplicate temporal columns (we have accident_date, accident_hour, etc.)\n",
        "        'date', 'time', 'accident_year',  # duplicate of accident_date components\n",
        "\n",
        "        # Duplicate location columns\n",
        "        'location_easting_osgr', 'location_northing_osgr',  # duplicate of longitude/latitude\n",
        "        'local_authority_district',  # duplicate of local_authority_ons_district\n",
        "\n",
        "        # Unnecessary for model training\n",
        "        'collision_index', 'collision_ref_no',  # unique identifiers\n",
        "        'collision_year',  # redundant with accident_date\n",
        "        'first_road_number', 'second_road_number',  # road numbers not useful for ML\n",
        "        'local_authority_highway',  # duplicate authority info\n",
        "        'police_force',  # not useful for prediction\n",
        "    ]\n",
        "\n",
        "    # Remove only columns that exist\n",
        "    existing_columns_to_remove = [col for col in columns_to_remove if col in df_optimized.columns]\n",
        "    df_optimized = df_optimized.drop(columns=existing_columns_to_remove)\n",
        "    print(f\"   Removed {len(existing_columns_to_remove)} duplicate/unnecessary columns\")\n",
        "\n",
        "    # 2. SELECT ONLY RELEVANT FEATURES FOR MODEL TRAINING\n",
        "    print(\"Selecting relevant features for ML...\")\n",
        "\n",
        "    # Categorize features for ML\n",
        "    target_variables = [\n",
        "        'risk_score', 'risk_category', 'collision_severity_decoded'\n",
        "    ]\n",
        "\n",
        "    temporal_features = [\n",
        "        'accident_date', 'accident_hour', 'time_period', 'accident_month',\n",
        "        'day_of_week_decoded', 'is_weekend'\n",
        "    ]\n",
        "\n",
        "    geographic_features = [\n",
        "        'longitude', 'latitude', 'local_authority_ons_district',\n",
        "        'urban_or_rural_area_decoded', 'lsoa_of_accident_location'\n",
        "    ]\n",
        "\n",
        "    vehicle_features = [\n",
        "        'final_vehicle_count', 'unique_vehicle_types', 'avg_driver_age',\n",
        "        'male_driver_ratio', 'unique_manoeuvres', 'unique_journey_purposes'\n",
        "    ]\n",
        "\n",
        "    casualty_features = [\n",
        "        'final_total_casualties', 'fatal_casualties_count', 'pedestrian_casualties_count',\n",
        "        'avg_casualty_age', 'unique_casualty_types'\n",
        "    ]\n",
        "\n",
        "    road_features = [\n",
        "        'first_road_class_decoded', 'speed_limit', 'speed_limit_category',\n",
        "        'road_type', 'trunk_road_flag_decoded', 'is_major_road', 'is_high_speed'\n",
        "    ]\n",
        "\n",
        "    junction_features = [\n",
        "        'junction_detail', 'junction_control_decoded', 'has_complex_junction',\n",
        "        'second_road_class_decoded'\n",
        "    ]\n",
        "\n",
        "    environmental_features = [\n",
        "        'light_conditions_decoded', 'weather_conditions_decoded',\n",
        "        'poor_visibility', 'adverse_weather', 'poor_road_condition',\n",
        "        'road_surface_conditions'\n",
        "    ]\n",
        "\n",
        "    other_features = [\n",
        "        'pedestrian_crossing', 'special_conditions_at_site', 'carriageway_hazards',\n",
        "        'did_police_officer_attend_scene_of_accident_decoded'\n",
        "    ]\n",
        "\n",
        "    # Combine all relevant features\n",
        "    all_relevant_features = (\n",
        "        temporal_features + geographic_features + vehicle_features +\n",
        "        casualty_features + road_features + junction_features +\n",
        "        environmental_features + other_features + target_variables\n",
        "    )\n",
        "\n",
        "    # Filter to only existing columns\n",
        "    existing_relevant_features = [col for col in all_relevant_features if col in df_optimized.columns]\n",
        "\n",
        "    # Add any remaining decoded columns we might have missed\n",
        "    remaining_decoded = [col for col in df_optimized.columns\n",
        "                        if col.endswith('_decoded') and col not in existing_relevant_features]\n",
        "\n",
        "    final_features = existing_relevant_features + remaining_decoded\n",
        "\n",
        "    # Create the optimized dataset\n",
        "    df_model_ready = df_optimized[final_features].copy()\n",
        "\n",
        "    # 3. FINAL DATA CLEANING\n",
        "    print(\"Final data cleaning...\")\n",
        "\n",
        "    # Handle any remaining missing values in numeric columns\n",
        "    numeric_columns = df_model_ready.select_dtypes(include=[np.number]).columns\n",
        "    for col in numeric_columns:\n",
        "        if df_model_ready[col].isna().sum() > 0:\n",
        "            df_model_ready[col] = df_model_ready[col].fillna(0)\n",
        "            print(f\"   Filled missing values in: {col}\")\n",
        "\n",
        "    # 4. REORDER COLUMNS FOR BETTER ORGANIZATION\n",
        "    print(\"Reordering columns logically...\")\n",
        "\n",
        "    optimal_order = [\n",
        "        # Temporal features\n",
        "        'accident_date', 'accident_hour', 'time_period', 'accident_month',\n",
        "        'day_of_week_decoded', 'is_weekend',\n",
        "\n",
        "        # Geographic features\n",
        "        'longitude', 'latitude', 'local_authority_ons_district',\n",
        "        'urban_or_rural_area_decoded', 'lsoa_of_accident_location',\n",
        "\n",
        "        # Road and infrastructure\n",
        "        'first_road_class_decoded', 'speed_limit', 'speed_limit_category',\n",
        "        'road_type', 'trunk_road_flag_decoded', 'is_major_road', 'is_high_speed',\n",
        "\n",
        "        # Junction information\n",
        "        'junction_detail', 'junction_control_decoded', 'has_complex_junction',\n",
        "        'second_road_class_decoded',\n",
        "\n",
        "        # Environmental conditions\n",
        "        'light_conditions_decoded', 'weather_conditions_decoded',\n",
        "        'road_surface_conditions', 'poor_visibility', 'adverse_weather',\n",
        "        'poor_road_condition',\n",
        "\n",
        "        # Vehicle information\n",
        "        'final_vehicle_count', 'unique_vehicle_types', 'avg_driver_age',\n",
        "        'male_driver_ratio', 'unique_manoeuvres', 'unique_journey_purposes',\n",
        "\n",
        "        # Casualty information\n",
        "        'final_total_casualties', 'fatal_casualties_count', 'pedestrian_casualties_count',\n",
        "        'avg_casualty_age', 'unique_casualty_types',\n",
        "\n",
        "        # Additional features\n",
        "        'pedestrian_crossing', 'special_conditions_at_site', 'carriageway_hazards',\n",
        "        'did_police_officer_attend_scene_of_accident_decoded',\n",
        "\n",
        "        # Target variables\n",
        "        'collision_severity_decoded', 'risk_score', 'risk_category'\n",
        "    ]\n",
        "\n",
        "    # Filter to existing columns and reorder\n",
        "    existing_optimal = [col for col in optimal_order if col in df_model_ready.columns]\n",
        "    remaining_columns = [col for col in df_model_ready.columns if col not in existing_optimal]\n",
        "\n",
        "    df_model_ready = df_model_ready[existing_optimal + remaining_columns]\n",
        "\n",
        "    # 6. GENERATE COMPREHENSIVE SUMMARY\n",
        "    print(\"\\nOPTIMIZED DATASET SUMMARY:\")\n",
        "    print(f\"   • Total records: {len(df_model_ready):,}\")\n",
        "    print(f\"   • Total features: {len(df_model_ready.columns)}\")\n",
        "    print(f\"   • File: {output_filename}\")\n",
        "\n",
        "    # Feature categories count\n",
        "    temporal_count = len([col for col in df_model_ready.columns if col in temporal_features])\n",
        "    geographic_count = len([col for col in df_model_ready.columns if col in geographic_features])\n",
        "    vehicle_count = len([col for col in df_model_ready.columns if col in vehicle_features])\n",
        "    road_count = len([col for col in df_model_ready.columns if col in road_features])\n",
        "    environmental_count = len([col for col in df_model_ready.columns if col in environmental_features])\n",
        "    decoded_count = len([col for col in df_model_ready.columns if col.endswith('_decoded')])\n",
        "\n",
        "    print(f\"\\nFEATURE BREAKDOWN:\")\n",
        "    print(f\"   • Temporal features: {temporal_count}\")\n",
        "    print(f\"   • Geographic features: {geographic_count}\")\n",
        "    print(f\"   • Vehicle features: {vehicle_count}\")\n",
        "    print(f\"   • Road features: {road_count}\")\n",
        "    print(f\"   • Environmental features: {environmental_count}\")\n",
        "    print(f\"   • Decoded columns: {decoded_count}\")\n",
        "\n",
        "    # Target variable info\n",
        "    if 'risk_category' in df_model_ready.columns:\n",
        "        high_risk = (df_model_ready['risk_category'] == 'High Risk').sum()\n",
        "        print(f\"   • High-risk cases: {high_risk:,} ({high_risk/len(df_model_ready)*100:.1f}%)\")\n",
        "\n",
        "    if 'collision_severity_decoded' in df_model_ready.columns:\n",
        "        severity_counts = df_model_ready['collision_severity_decoded'].value_counts()\n",
        "        print(f\"   • Severity distribution: {dict(severity_counts)}\")\n",
        "\n",
        "    print(f\" FIRST 5 COLUMNS: {list(df_model_ready.columns[:5])}\")\n",
        "    print(f\"LAST 5 COLUMNS: {list(df_model_ready.columns[-5:])}\")\n",
        "\n",
        "    return df_model_ready\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV0IH1bkvmzt",
        "outputId": "625e1fd1-7c6d-4fa3-e9b0-fe15e2befd21"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATING OPTIMIZED DATASET FOR MODEL TRAINING...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the optimized dataset\n",
        "df_model_ready = create_optimized_model_dataset(final_data, \"road_safety_model_ready.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKfJPoM1vp4i",
        "outputId": "401799a1-c5a6-42b5-88c9-08d477e89a6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing duplicate and unnecessary columns...\n",
            "   Removed 11 duplicate/unnecessary columns\n",
            "Selecting relevant features for ML...\n",
            "Final data cleaning...\n",
            "   Filled missing values in: unique_manoeuvres\n",
            "   Filled missing values in: avg_casualty_age\n",
            "   Filled missing values in: unique_casualty_types\n",
            "Reordering columns logically...\n",
            "\n",
            "OPTIMIZED DATASET SUMMARY:\n",
            "   • Total records: 52,657\n",
            "   • Total features: 46\n",
            "   • File: road_safety_model_ready.csv\n",
            "\n",
            "FEATURE BREAKDOWN:\n",
            "   • Temporal features: 6\n",
            "   • Geographic features: 5\n",
            "   • Vehicle features: 6\n",
            "   • Road features: 6\n",
            "   • Environmental features: 6\n",
            "   • Decoded columns: 11\n",
            "   • High-risk cases: 13,597 (25.8%)\n",
            "   • Severity distribution: {'Slight': np.int64(40336), 'Serious': np.int64(11691), 'Fatal': np.int64(630)}\n",
            " FIRST 5 COLUMNS: ['accident_date', 'accident_hour', 'time_period', 'accident_month', 'day_of_week_decoded']\n",
            "LAST 5 COLUMNS: ['did_police_officer_attend_scene_of_accident_decoded', 'collision_severity_decoded', 'risk_score', 'risk_category', 'road_type_decoded']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_model_ready.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeJgsayTv37-",
        "outputId": "c7879606-9cdd-4db1-c08a-a7eb9203529e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['accident_date', 'accident_hour', 'time_period', 'accident_month',\n",
              "       'day_of_week_decoded', 'is_weekend', 'longitude', 'latitude',\n",
              "       'local_authority_ons_district', 'urban_or_rural_area_decoded',\n",
              "       'lsoa_of_accident_location', 'first_road_class_decoded', 'speed_limit',\n",
              "       'speed_limit_category', 'trunk_road_flag_decoded', 'is_major_road',\n",
              "       'is_high_speed', 'junction_detail', 'junction_control_decoded',\n",
              "       'has_complex_junction', 'second_road_class_decoded',\n",
              "       'light_conditions_decoded', 'weather_conditions_decoded',\n",
              "       'road_surface_conditions', 'poor_visibility', 'adverse_weather',\n",
              "       'poor_road_condition', 'final_vehicle_count', 'unique_vehicle_types',\n",
              "       'avg_driver_age', 'male_driver_ratio', 'unique_manoeuvres',\n",
              "       'unique_journey_purposes', 'final_total_casualties',\n",
              "       'fatal_casualties_count', 'pedestrian_casualties_count',\n",
              "       'avg_casualty_age', 'unique_casualty_types', 'pedestrian_crossing',\n",
              "       'special_conditions_at_site', 'carriageway_hazards',\n",
              "       'did_police_officer_attend_scene_of_accident_decoded',\n",
              "       'collision_severity_decoded', 'risk_score', 'risk_category',\n",
              "       'road_type_decoded'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = [\n",
        "    'lsoa_of_accident_location',\n",
        "    'special_conditions_at_site',\n",
        "    'carriageway_hazards',\n",
        "    'unique_journey_purposes',\n",
        "    'speed_limit_category'\n",
        "]\n",
        "\n",
        "df_finals = df_model_ready.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "df_finals.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAizLU35v8gl",
        "outputId": "e0713693-bcb9-4ff5-da23-6fd5b836cad3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52657, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_finals.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcmT_O8_v--v",
        "outputId": "b79ece48-f870-4cc9-99fa-e96d04079d8f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['accident_date', 'accident_hour', 'time_period', 'accident_month',\n",
              "       'day_of_week_decoded', 'is_weekend', 'longitude', 'latitude',\n",
              "       'local_authority_ons_district', 'urban_or_rural_area_decoded',\n",
              "       'first_road_class_decoded', 'speed_limit', 'trunk_road_flag_decoded',\n",
              "       'is_major_road', 'is_high_speed', 'junction_detail',\n",
              "       'junction_control_decoded', 'has_complex_junction',\n",
              "       'second_road_class_decoded', 'light_conditions_decoded',\n",
              "       'weather_conditions_decoded', 'road_surface_conditions',\n",
              "       'poor_visibility', 'adverse_weather', 'poor_road_condition',\n",
              "       'final_vehicle_count', 'unique_vehicle_types', 'avg_driver_age',\n",
              "       'male_driver_ratio', 'unique_manoeuvres', 'final_total_casualties',\n",
              "       'fatal_casualties_count', 'pedestrian_casualties_count',\n",
              "       'avg_casualty_age', 'unique_casualty_types', 'pedestrian_crossing',\n",
              "       'did_police_officer_attend_scene_of_accident_decoded',\n",
              "       'collision_severity_decoded', 'risk_score', 'risk_category',\n",
              "       'road_type_decoded'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "output_filename = \"df_finals.csv\"\n",
        "df_model_ready.to_csv(output_filename, index=False)\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "daIK6V3CwLoo",
        "outputId": "8cb7637c-bef2-4762-f18f-e8d90e174a8e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5b773d9a-2a89-4066-aaf9-cdd77c42d197\", \"df_finals.csv\", 15617339)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n6vx2zfjwVQ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}